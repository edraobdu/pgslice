"""SQL INSERT statement generation with proper escaping."""

import json
from datetime import date, datetime, time
from typing import Any
from uuid import UUID

from ..db.schema import SchemaIntrospector
from ..graph.models import RecordData
from ..utils.logging_config import get_logger

logger = get_logger(__name__)


class SQLGenerator:
    """Generates INSERT statements from record data."""

    def __init__(
        self, schema_introspector: SchemaIntrospector, batch_size: int = 100
    ) -> None:
        """
        Initialize SQL generator.

        Args:
            schema_introspector: Schema introspection utility for table metadata
            batch_size: Number of rows per INSERT statement (0 or -1 = unlimited)
        """
        self.introspector = schema_introspector
        # 0 or -1 means unlimited batch size
        self.batch_size = batch_size if batch_size > 0 else 999999

    def generate_bulk_insert(self, records: list[RecordData]) -> str:
        """
        Generate a single bulk INSERT statement for multiple records.

        Args:
            records: List of records from the SAME table

        Returns:
            SQL INSERT statement with multiple VALUES rows
        """
        if not records:
            return ""

        # All records are from same table, use first for metadata
        first_record = records[0]
        schema = first_record.identifier.schema_name
        table = first_record.identifier.table_name

        # Get table metadata for primary keys
        table_metadata = self.introspector.get_table_metadata(schema, table)

        # Build column list (same for all rows)
        columns = sorted(first_record.data.keys())
        columns_sql = ", ".join(f'"{col}"' for col in columns)

        # Build VALUES rows
        values_rows = []
        for record in records:
            values = [self._format_value(record.data.get(col)) for col in columns]
            values_sql = ", ".join(values)
            values_rows.append(f"    ({values_sql})")

        values_clause = ",\n".join(values_rows)

        # Build ON CONFLICT clause
        if table_metadata.primary_keys:
            pk_columns = ", ".join(f'"{pk}"' for pk in table_metadata.primary_keys)
            conflict_clause = f"\nON CONFLICT ({pk_columns}) DO NOTHING"
        else:
            conflict_clause = ""

        # Add comment header with table info
        full_table_name = f'"{schema}"."{table}"'
        comment = f"-- Table: {full_table_name} ({len(records)} record{'s' if len(records) != 1 else ''})"

        # Combine into final statement
        sql = (
            f"{comment}\n"
            f'INSERT INTO {full_table_name} ({columns_sql})\n'
            f"VALUES\n{values_clause}"
            f"{conflict_clause};"
        )

        return sql

    def generate_batch(
        self, records: list[RecordData], include_transaction: bool = True
    ) -> str:
        """
        Generate SQL for multiple records with proper ordering and bulk INSERTs.

        Args:
            records: List of RecordData in dependency order
            include_transaction: Whether to wrap in BEGIN/COMMIT

        Returns:
            Complete SQL script with all bulk INSERT statements
        """
        from collections import defaultdict

        logger.info(f"Generating SQL for {len(records)} records (batch_size={self.batch_size})")

        sql_statements = []

        # Add header
        header = [
            "-- Generated by snippy",
            f"-- Date: {datetime.now().isoformat()}",
            f"-- Records: {len(records)}",
            f"-- Batch size: {self.batch_size}",
            "",
        ]

        sql_statements.extend(header)

        # Add BEGIN if transaction requested
        if include_transaction:
            sql_statements.append("BEGIN;")
            sql_statements.append("")

        # Group records by table (preserving dependency order within each table)
        records_by_table: dict[tuple[str, str], list[RecordData]] = defaultdict(list)
        for record in records:
            key = (record.identifier.schema_name, record.identifier.table_name)
            records_by_table[key].append(record)

        # Generate bulk INSERTs for each table with batching
        for (schema, table), table_records in records_by_table.items():
            # Split into batches
            for i in range(0, len(table_records), self.batch_size):
                batch = table_records[i : i + self.batch_size]
                bulk_insert = self.generate_bulk_insert(batch)
                sql_statements.append(bulk_insert)
                sql_statements.append("")  # Blank line between batches

        # Add COMMIT if transaction requested
        if include_transaction:
            sql_statements.append("COMMIT;")

        result = "\n".join(sql_statements)
        logger.info(f"Generated SQL script ({len(result)} bytes)")
        return result

    def _format_value(self, value: Any) -> str:
        """
        Format a Python value as SQL literal.

        Args:
            value: Python value to format

        Returns:
            SQL literal string

        Handles:
        - NULL values
        - Booleans (TRUE/FALSE)
        - Numbers (int, float)
        - Strings (with proper escaping)
        - Dates, times, timestamps
        - UUIDs
        - JSON/JSONB (dict, list)
        - Bytea (bytes)
        """
        if value is None:
            return "NULL"

        elif isinstance(value, bool):
            # Must come before int check (bool is subclass of int)
            return "TRUE" if value else "FALSE"

        elif isinstance(value, int):
            return str(value)

        elif isinstance(value, float):
            # Handle special float values
            if value != value:  # NaN
                return "'NaN'"
            elif value == float("inf"):
                return "'Infinity'"
            elif value == float("-inf"):
                return "'-Infinity'"
            return str(value)

        elif isinstance(value, str):
            # Escape single quotes by doubling them
            escaped = value.replace("'", "''")
            # Also escape backslashes for PostgreSQL
            escaped = escaped.replace("\\", "\\\\")
            return f"'{escaped}'"

        elif isinstance(value, datetime):
            # ISO format with timezone
            return f"'{value.isoformat()}'"

        elif isinstance(value, date):
            return f"'{value.isoformat()}'"

        elif isinstance(value, time):
            return f"'{value.isoformat()}'"

        elif isinstance(value, UUID):
            return f"'{str(value)}'"

        elif isinstance(value, (dict, list)):
            # JSON/JSONB - serialize and escape
            json_str = json.dumps(value)
            escaped = json_str.replace("'", "''")
            return f"'{escaped}'"

        elif isinstance(value, bytes):
            # Bytea - use hex format
            hex_str = value.hex()
            return f"'\\x{hex_str}'"

        elif isinstance(value, memoryview):
            # Convert memoryview to bytes
            return self._format_value(bytes(value))

        else:
            # Fallback: convert to string and escape
            logger.warning(f"Unknown type {type(value)} for value {value}, converting to string")
            return self._format_value(str(value))
